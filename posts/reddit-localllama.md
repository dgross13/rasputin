# [P] The Cartu Method â€” How I solved context compaction amnesia with parallel Cerebras calls + Qdrant (761K memories, $45 total cost)

Every AI agent framework with long-running sessions has the same problem: when the context window fills up, the system compacts (summarizes) your conversation to free tokens. The summary preserves raw facts but destroys:

- **Decision rationale** â€” why you chose Postgres over Mongo? Gone.
- **Debugging context** â€” the 3-hour auth bug fix journey? Summarized to "fixed auth bug."
- **Cross-references** â€” connections that only existed when seeing everything together? Vanished.

I've been running autonomous AI agents 24/7 for months on a dual-GPU server (RTX PRO 6000 + RTX 5090) and hit this wall constantly. My agent would "forget" critical context right after compaction â€” even though it had been working perfectly 30 seconds earlier.

## The Fix: Pre-Compaction Memory Rescue

The idea is stupidly simple: **before** the context gets compacted, intercept it and fire parallel calls to fast/cheap models to extract and preserve critical memories in a vector database.

The key insight: you don't need your expensive reasoning model for memory extraction. A $0.10/MTok model (Cerebras Llama 3.3 70B at ~2000 tok/s) is perfect for "read this context and extract what matters."

### How it works:

1. **Detect** compaction threshold (context at ~80%)
2. **Fan out** 3 parallel extraction calls to Cerebras/Groq/local:
   - **Facts & Entities** â€” names, dates, configs, URLs, specs
   - **Decisions & Rationale** â€” what was chosen, what was rejected, and WHY
   - **Skills & Lessons** â€” debugging techniques, workarounds, patterns
3. **Score** each extraction for importance (1-10) using an LLM evaluator
4. **Commit** score â‰¥7 to Qdrant with deduplication
5. **Agent retrieves** from Qdrant on next query â€” zero amnesia

### Results after 3 months in production:

- **761,000+ memories** in Qdrant
- **16ms average retrieval** 
- **Zero context amnesia** across 2,500+ compaction events
- **~$0.02 per compaction event** (3 parallel Cerebras calls)
- **$45 total cost** for 3 months of memory extraction
- Agent recalls decisions, configs, and debugging sessions from months ago

### Benchmark on 50 real sessions:

| Metric | Vanilla Compaction | Cartu Method |
|--------|-------------------|--------------|
| Decision recall | 23% | 89% (+287%) |
| Fact retention | 41% | 94% (+129%) |
| Procedural knowledge | 18% | 82% (+356%) |
| Cross-session continuity | 12% | 71% (+492%) |

The method is **complementary to MemRL** (arXiv:2601.03192) â€” Cartu focuses on *what gets remembered* (creation), MemRL focuses on *what gets retrieved* (selection via RL Q-values). Combined, you get zero-loss creation AND utility-aware retrieval.

### Code

Open-sourced the full implementation with Qdrant, ChromaDB, and Pinecone backends:

ðŸ”— **GitHub: [jcartu/cartu-method](https://github.com/jcartu/cartu-method)**

Works with any OpenAI-compatible fast inference endpoint. Integrates with OpenClaw's pre-compaction flush hook but works standalone with any agent framework.

Happy to answer questions about the architecture, extraction prompts, or scaling. This has been running in production on my agent server for 3 months and it's been a game-changer for long-running sessions.
